{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c036ad77",
   "metadata": {},
   "source": [
    "# Ave, CELEBA! Experiment with MMD regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93dbbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from src.models import UNet, ResNet_D\n",
    "from src.utils import Config, weights_init_D, freeze\n",
    "from src.data import DatasetSampler\n",
    "from src.train_gauss_kernel import train_gauss_kernel\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import dnnlib\n",
    "import legacy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031d185",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "GAMMA = 0.1\n",
    "BATCH_SIZE = 28\n",
    "RESNET_ENCODER_LATENT = 2\n",
    "INNER_ITERATIONS = 10\n",
    "NUM_EPOCHS = 1\n",
    "GPU_DEVICE = 0\n",
    "WEIGHT_NORM = 0.1\n",
    "Z_STD = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25ebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = Config()\n",
    "\n",
    "CONFIG.K = 3\n",
    "CONFIG.LAMBDAS = [0.25,0.5,0.25]\n",
    "\n",
    "CONFIG.DATASET_PATH ='../../../data/ave_celeba_green_v2/' \n",
    "CONFIG.DATASET = 'ave_celeba'\n",
    "CONFIG.BATCH_SIZE = BATCH_SIZE\n",
    "CONFIG.IMG_SIZE =64\n",
    "CONFIG.NC =3\n",
    "\n",
    "CONFIG.LR_POTENTIAL = 2e-4\n",
    "CONFIG.LR_ENCODER = 2e-4\n",
    "CONFIG.BETAS = (0.2, 0.99)\n",
    "\n",
    "CONFIG.FLAG_LATENT = True\n",
    "CONFIG.ZC = 1\n",
    "CONFIG.LATENT_SIZE = 512\n",
    "CONFIG.GENERATOR_PATH = \"../../../stylegan2_ada_pytorch_before/training-runs/00011-aligned_celeba-stylegan2/network-snapshot-008800.pkl\"\n",
    "\n",
    "\n",
    "CONFIG.NUM_EPOCHS = NUM_EPOCHS\n",
    "CONFIG.INNER_ITERATIONS = INNER_ITERATIONS\n",
    "CONFIG.GAMMA = GAMMA\n",
    " \n",
    "CONFIG.WEIGHT_NORM = WEIGHT_NORM   \n",
    "CONFIG.Z_STD = Z_STD\n",
    "CONFIG.RESNET_ENCODER_LATENT = RESNET_ENCODER_LATENT\n",
    "\n",
    " \n",
    "\n",
    "CONFIG.GPU_DEVICE = GPU_DEVICE\n",
    "assert torch.cuda.is_available()\n",
    "CONFIG.DEVICE = f'cuda:{CONFIG.GPU_DEVICE}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715447a0",
   "metadata": {},
   "source": [
    "## 2. Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a255a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG.FLAG_LATENT:\n",
    "    with dnnlib.util.open_url(CONFIG.GENERATOR_PATH) as f:\n",
    "        G =  legacy.load_network_pkl(f)['G_ema'].to(CONFIG.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803b16f",
   "metadata": {},
   "source": [
    "## 3. Potential and Conditional Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc7d30f",
   "metadata": {},
   "source": [
    "### 3.1 potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nets_for_pot = [ResNet_D(size=CONFIG.IMG_SIZE,\n",
    "                  nc=CONFIG.NC,\n",
    "                  nfilter=64, \n",
    "                  nfilter_max=512, \n",
    "                  res_ratio=0.1,\n",
    "                  n_output=1,bn_flag=False,pn_flag=False).to(CONFIG.DEVICE)\n",
    "                  for i in range(CONFIG.K)]\n",
    "\n",
    "\n",
    "# initialization\n",
    "for f in nets_for_pot: \n",
    "    weights_init_D(f)\n",
    "\n",
    "# optimization\n",
    "param_nets = [net.parameters() for net in nets_for_pot]\n",
    "nets_for_pot_opt = torch.optim.Adam(itertools.chain(*param_nets),\n",
    "                                lr=CONFIG.LR_POTENTIAL,\n",
    "                                betas=CONFIG.BETAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5419dc",
   "metadata": {},
   "source": [
    "### 3.2 Conditional Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc00a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = [ResNet_D(size=CONFIG.IMG_SIZE,\n",
    "                  nc=CONFIG.NC + CONFIG.ZC,\n",
    "                  nfilter=64, \n",
    "                  nfilter_max=512, \n",
    "                  res_ratio=0.1,\n",
    "                  n_output=2*CONFIG.LATENT_SIZE,\n",
    "                   bn_flag=True, pn_flag=True).to(CONFIG.DEVICE)\n",
    "           for k in range(CONFIG.K)]\n",
    "\n",
    "# initialization\n",
    "for k in range(CONFIG.K): \n",
    "    weights_init_D(encoder[k])\n",
    "\n",
    "# optimization\n",
    "encoder_params = [enc.parameters() for enc in encoder]\n",
    "encoder_opt = torch.optim.Adam( itertools.chain(*encoder_params), \n",
    "                              lr=CONFIG.LR_ENCODER,\n",
    "                              betas=CONFIG.BETAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e412a5c9",
   "metadata": {},
   "source": [
    "## 4. Data samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2070369",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(CONFIG.IMG_SIZE),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(lambda x: torch.clip(x,0,1))\n",
    "])\n",
    "\n",
    "data_samplers=[]\n",
    "for k in tqdm(range(CONFIG.K)):\n",
    "    dataset = torchvision.datasets.ImageFolder(os.path.join(CONFIG.DATASET_PATH,f\"ave_celeba_{k}/\"),\n",
    "                                               transform=transform)\n",
    "    data_samplers.append(DatasetSampler(dataset, flag_label=True, batch_size=256 ,num_workers=40))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d312deb",
   "metadata": {},
   "source": [
    "## 5. Wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_exp = f\"gauss_Dist_GAMMA_{GAMMA}_Z_STD_{Z_STD}_BS_{BATCH_SIZE}_NZ_{RESNET_ENCODER_LATENT}\"\n",
    "CONFIG.NAME_EXP = name_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6c31e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"BNOT\" ,\n",
    "           name=name_exp ,\n",
    "           config=CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebd72e",
   "metadata": {},
   "source": [
    "## 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da18a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gauss_kernel(nets_for_pot,\n",
    "                nets_for_pot_opt,\n",
    "                encoder,\n",
    "                encoder_opt,\n",
    "                data_samplers,\n",
    "                G,\n",
    "                CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adcdb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
