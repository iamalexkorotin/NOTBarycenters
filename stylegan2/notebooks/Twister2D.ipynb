{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457df6e6",
   "metadata": {},
   "source": [
    "# Strong barycenter estimation on toy examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.distributions as TD\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "%matplotlib inline\n",
    "\n",
    "from typing import Dict, Any, Literal, List, Tuple, Union, Optional\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from src.utils import Config, make_f_pot, freeze, unfreeze\n",
    "from src.models import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797fceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(\n",
    "    seed: int,\n",
    "    *,\n",
    "    avoid_benchmark_noise: bool = False,\n",
    "    only_deterministic_algorithms: bool = False\n",
    "):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = not avoid_benchmark_noise\n",
    "    torch.use_deterministic_algorithms(only_deterministic_algorithms, warn_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c493ebcd",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gauss(mu, cov, n):\n",
    "    \"\"\"\n",
    "    mu - torch.Size([2])\n",
    "    cov - torch.Size([2,2])\n",
    "    n - int (amount of samples)\n",
    "    \"\"\"\n",
    "    dist =  TD.MultivariateNormal(mu, cov)\n",
    "    return dist.sample(torch.Size([n]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8aaf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_initial_data(mus,covs,n):\n",
    "    \"\"\"\n",
    "    mus - list of torch.Size([2])\n",
    "    covs - list of torch.Size([2,2])\n",
    "    n - int (amount of samples)\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx,mu,cov in zip(range(len(mus)), mus,covs):\n",
    "        d = sample_gauss(mu, cov, n)\n",
    "        plt.scatter(d[:,0],d[:,1],edgecolor='black',label=f'distribution {idx+1}')\n",
    "        plt.grid()\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b41091",
   "metadata": {},
   "source": [
    "## Twister experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = Config()\n",
    "\n",
    "CONFIG.GPU_DEVICE = 0\n",
    "assert torch.cuda.is_available()\n",
    "CONFIG.DEVICE = f'cuda:{CONFIG.GPU_DEVICE}'\n",
    "\n",
    "CONFIG.K = 3  # amount of distributions\n",
    "CONFIG.LAMBDAS = [0.3333,0.3333,0.3333]\n",
    "CONFIG.DIM = 2\n",
    "CONFIG.INPUT_DIM = CONFIG.DIM\n",
    "CONFIG.HIDDEN_DIMS = [128,128]\n",
    "CONFIG.OUTPUT_DIM_POT = 1\n",
    "CONFIG.OUTPUT_DIM_MAP = CONFIG.DIM\n",
    "CONFIG.LR = 1e-3\n",
    "CONFIG.NUM_SAMPLES = 10_000\n",
    "CONFIG.NUM_EPOCHS = 1200\n",
    "CONFIG.BATCH_SIZE= 1024\n",
    "CONFIG.INNER_ITERATIONS = 3\n",
    "\n",
    "CONFIG.PRIOR_MEAN = torch.tensor([5., 5.], device=CONFIG.DEVICE)\n",
    "CONFIG.PRIOR_COV = 2 * torch.eye(2, device=CONFIG.DEVICE)\n",
    "CONFIG.CONDITIONAL_COV = .1 * torch.eye(2, device=CONFIG.DEVICE)\n",
    "CONFIG.KL_REG_STRENGTH = 0.0\n",
    "CONFIG.ED_SAMPLE_REG_STRENGTH = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, *hidden_dims: int):\n",
    "        \"\"\"Sequential linear layers with the ReLU activation.\n",
    "        \n",
    "        ReLU is applied between all layers. A number of layers equals\n",
    "        `len(hidden_dims) - 1`. The first and the last hidden dims are treated as the \n",
    "        input and the output dimensions of the backbone.\n",
    "        \"\"\"\n",
    "        assert len(hidden_dims) >= 2\n",
    "        super().__init__()\n",
    "        \n",
    "        inp, *hidden_dims = hidden_dims\n",
    "        self._layers = nn.Sequential(nn.Linear(inp, hidden_dims[0]))\n",
    "        for inp, out in zip(hidden_dims[:-1], hidden_dims[1:]):\n",
    "            self._layers.append(nn.ReLU(inplace=True))\n",
    "            self._layers.append(nn.Linear(inp, out))\n",
    "        \n",
    "    def forward(self, x): return self._layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092420e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OTMap(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp_dim: int = None,\n",
    "        hidden_dims: List[int] = None,\n",
    "        out_dim: int = None,\n",
    "        *args, **kwargs,\n",
    "    ):\n",
    "        \"\"\"Initialize OT map class.\n",
    "        \n",
    "        Args:\n",
    "            inp_dim: a dimensionality of the source space.\n",
    "            out_dim: a dimensionality of the target space.\n",
    "            hidden_dims: hidden dimensions.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.FloatTensor,\n",
    "        reg: bool = False,\n",
    "    ) -> Union[torch.FloatTensor, Tuple[torch.FloatTensor, torch.FloatTensor]]:\n",
    "        \"\"\"Compute OT Map.\n",
    "        \n",
    "        If the map is weak, return one sample per input item.\n",
    "        \n",
    "        Args:\n",
    "            x: tensor of shape (bs, inp_dim)\n",
    "            reg: wether to return the regularization term\n",
    "        \n",
    "        Returns:\n",
    "            tensor of shape (bs, out_dim) [and regularization term]\n",
    "        \"\"\"\n",
    "        \n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426fec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeterministicMap(OTMap):\n",
    "    def __init__(self, inp_dim: int, hidden_dims: List[int], out_dim: int):\n",
    "        super().__init__()\n",
    "        self._bb = MLP(inp_dim, *hidden_dims, out_dim)\n",
    "        \n",
    "    def forward(self, x, reg: bool = False):\n",
    "        out = self._bb(x)\n",
    "        if reg:\n",
    "            return out, torch.tensor(0.0, device=x.device)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d04f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianMap(OTMap):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp_dim: int,\n",
    "        hidden_dims: List[int],\n",
    "        out_dim: int,\n",
    "        prior_mean: torch.FloatTensor,\n",
    "        prior_cov: torch.FloatTensor,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._out_dim = out_dim\n",
    "        out_dim_combined = (\n",
    "            out_dim                         # mean\n",
    "            + out_dim * (out_dim + 1) // 2  # covariance matrix\n",
    "        )\n",
    "        self._bb = MLP(inp_dim, *hidden_dims, out_dim_combined)\n",
    "        self._m_pr = prior_mean\n",
    "        self._cov_pr = prior_cov\n",
    "        \n",
    "    def forward(self, x, reg: bool = False):\n",
    "        bs = x.shape[0]\n",
    "        dev = x.device\n",
    "        \n",
    "        mean_cov = self._bb(x)\n",
    "        \n",
    "        mean = mean_cov[:, :self._out_dim]\n",
    "        cov_l = torch.zeros(\n",
    "            (bs, self._out_dim, self._out_dim),\n",
    "            device=dev,\n",
    "        )\n",
    "        tril_idx = torch.tril_indices(self._out_dim, self._out_dim, device=dev)\n",
    "        cov_l[:, tril_idx[0], tril_idx[1]] = mean_cov[:, self._out_dim:]\n",
    "        cov = cov_l @ cov_l.mT\n",
    "        \n",
    "        noise = torch.randn(bs, self._out_dim, device=dev)\n",
    "        out = mean + torch.einsum(\"...ij,...j->...i\", cov_l, noise)\n",
    "        kl = self.kl_reg(mean, cov, self._m_pr, self._cov_pr)\n",
    "        \n",
    "        if reg:\n",
    "            return out, kl\n",
    "        return out\n",
    "        \n",
    "    \n",
    "    # tested with torch.distributions.kl_divergence\n",
    "    @staticmethod\n",
    "    def kl_reg(\n",
    "        m_post: torch.FloatTensor,\n",
    "        cov_post: torch.FloatTensor,\n",
    "        m_pr: torch.FloatTensor,\n",
    "        cov_pr: torch.FloatTensor,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        means have shape (bs, k), covariance matrices have shape (k, k)\n",
    "        \"\"\"\n",
    "\n",
    "        _, pr_log_det = torch.linalg.slogdet(cov_pr)\n",
    "        _, post_log_det = torch.linalg.slogdet(cov_post)\n",
    "        mean_diff = m_pr - m_post  # (bs, k)\n",
    "        mT_sigma_pr_inv = torch.linalg.solve(cov_pr, mean_diff, left=False)\n",
    "        assert mT_sigma_pr_inv.shape == mean_diff.shape  # (bs, k)\n",
    "\n",
    "        return 0.5 * (\n",
    "            torch.einsum(\"...ii\", torch.linalg.solve(cov_pr, cov_post))\n",
    "            + (mT_sigma_pr_inv * mean_diff).sum(1)\n",
    "            - m_pr.shape[-1]\n",
    "            + pr_log_det - post_log_det\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoiseInputMap(OTMap):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inp_dim: int,\n",
    "        hidden_dims: List[int],\n",
    "        out_dim: int,\n",
    "        prior: torch.distributions.Distribution,\n",
    "        noise_dim: Optional[int] = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._noise_dim = noise_dim or inp_dim\n",
    "        self._prior = prior\n",
    "        self._bb = MLP(inp_dim + self._noise_dim, *hidden_dims, out_dim)\n",
    "        \n",
    "    def forward(self, x, reg: bool = False):\n",
    "        bs = x.shape[0]\n",
    "        dev = x.device\n",
    "        \n",
    "        noise = torch.randn(bs, self._noise_dim, device=dev)\n",
    "        x = torch.cat((x, noise), dim=-1)\n",
    "        out = self._bb(x)\n",
    "        ed = self.energy_dist_reg_sample(out)\n",
    "        \n",
    "        if reg:\n",
    "            return out, ed\n",
    "        return out\n",
    "        \n",
    "    def energy_dist_reg_sample(\n",
    "        self,\n",
    "        sample: torch.FloatTensor,\n",
    "    ):\n",
    "        \"\"\"Compute energy distance (only sample-dependent terms) using sample estimate.\n",
    "\n",
    "        Args:\n",
    "            sample: has shape (bs, d)\n",
    "            prior: torch distribution of item shape (d,)\n",
    "\n",
    "        Returns:\n",
    "            tensor of shape (bs,)\n",
    "        \"\"\"\n",
    "        pr_sample_1, pr_sample_2 = self._prior.sample((2, *sample.shape[:-1]))\n",
    "        l12 = (sample - pr_sample_1).norm(dim=1)\n",
    "        l11 = (pr_sample_1 - pr_sample_2).norm(dim=1)\n",
    "        return 2 * l12 - l11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c04b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_SLOPE = 0.4\n",
    "\n",
    "def norm2theta(norms):\n",
    "    return H_SLOPE * norms\n",
    "\n",
    "def rotate_batch(Rs, Xs):\n",
    "    if len(Xs.shape) == 1:\n",
    "        Xs = Xs[None]\n",
    "    assert len(Xs.shape) == 2\n",
    "    assert Xs.size(1) == 2\n",
    "    assert Xs.size(0) == Rs.size(0)\n",
    "    assert len(Rs.shape) == 3\n",
    "    assert Rs.size(1) == Rs.size(2) == 2\n",
    "    return torch.matmul(\n",
    "        Xs.unsqueeze(1), \n",
    "        Rs.transpose(1, 2)).squeeze(1)\n",
    "\n",
    "def cossin2R(cos, sin):\n",
    "    assert cos.shape == sin.shape\n",
    "    assert len(cos.shape) == 1\n",
    "    return torch.stack([cos, -sin, sin, cos]).T.view(-1, 2, 2)\n",
    "    \n",
    "def lin_space_rotator(Xs, pos=True):\n",
    "    if len(Xs.shape) == 1:\n",
    "        Xs = Xs[None]\n",
    "    assert len(Xs.shape) == 2\n",
    "    assert Xs.size(1) == 2\n",
    "    X_norms = torch.norm(Xs, dim=-1)\n",
    "    thetas = norm2theta(X_norms)\n",
    "    if not pos:\n",
    "        thetas = - thetas\n",
    "    cos = torch.cos(thetas)\n",
    "    sin = torch.sin(thetas)\n",
    "    Rs = cossin2R(cos, sin)\n",
    "    return rotate_batch(Rs, Xs)\n",
    "\n",
    "def h(Xs):\n",
    "    return lin_space_rotator(Xs, pos=True)\n",
    "\n",
    "def h_inv(Zs):\n",
    "    return lin_space_rotator(Zs, pos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1distrib = TD.Normal(\n",
    "        torch.tensor([0., 4]).to(CONFIG.DEVICE),\n",
    "        torch.tensor([1., 1.]).to(CONFIG.DEVICE))\n",
    "\n",
    "Z2distrib = TD.Normal(\n",
    "        torch.tensor([3.46, -2.]).to(CONFIG.DEVICE),\n",
    "        torch.tensor([1., 1.]).to(CONFIG.DEVICE))\n",
    "\n",
    "Z3distrib = TD.Normal(\n",
    "        torch.tensor([-3.46, -2]).to(CONFIG.DEVICE),\n",
    "        torch.tensor([1., 1.]).to(CONFIG.DEVICE))\n",
    "\n",
    "Zgtdistrib = TD.Normal(\n",
    "        torch.tensor([0.0, 0.0]).to(CONFIG.DEVICE),\n",
    "        torch.tensor([1., 1.]).to(CONFIG.DEVICE))\n",
    "\n",
    "twister_data = [Z1distrib, Z2distrib, Z3distrib]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_initial_data(n):\n",
    "    \"\"\"\n",
    "    mus - list of torch.Size([2])\n",
    "    covs - list of torch.Size([2,2])\n",
    "    n - int (amount of samples)\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx,k in enumerate(range(CONFIG.K)):\n",
    "        d = twister_data[k].sample([n])\n",
    "        d = h_inv(d)\n",
    "        plt.scatter(d[:,0].cpu(),d[:,1].cpu(),edgecolor='black',label=f'distribution {idx+1}')\n",
    "        plt.axis(\"equal\")\n",
    "        plt.grid()\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740c866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_initial_data(2_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68fda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0, avoid_benchmark_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d548357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pots(nn.Module):\n",
    "    \n",
    "    # TODO: optimize when 2 potentials\n",
    "    def __init__(self, bary_weights, *dims):\n",
    "        assert len(bary_weights) > 1\n",
    "        super().__init__()\n",
    "        self._lambdas = bary_weights\n",
    "        self._nets = nn.ModuleList([MLP(*dims) for _ in range(len(bary_weights))])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        assert 0 <= idx < len(self._lambdas)\n",
    "        \n",
    "        def f_pot(x):\n",
    "            res = 0.0\n",
    "            for i, (net, lmbd) in enumerate(zip(self._nets, self._lambdas)):\n",
    "\n",
    "                if i == idx:\n",
    "                    res += net(x)\n",
    "                else:\n",
    "                    res -= lmbd * net(x) / (len(self._lambdas) - 1) / self._lambdas[idx]\n",
    "            return res\n",
    "        \n",
    "        return f_pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77de17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opt_sched(model, total_steps):\n",
    "    opt = torch.optim.Adam(model.parameters(), CONFIG.LR)\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        opt,\n",
    "        CONFIG.LR,\n",
    "        total_steps=total_steps,\n",
    "    )\n",
    "    \n",
    "    return opt, sched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e00ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    maps: OTMap, maps_opt, maps_sched, \n",
    "    pots: Pots, pots_opt, pots_sched,\n",
    "    reg_coeff: float = 0.0,\n",
    "):\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in tqdm(range(CONFIG.NUM_EPOCHS)):\n",
    "        \n",
    "        freeze(pots)\n",
    "        unfreeze(maps)\n",
    "        \n",
    "        #inner loop\n",
    "        for it in range(CONFIG.INNER_ITERATIONS):\n",
    "            \n",
    "            # data sampling\n",
    "            data = [\n",
    "                h_inv(twister_data[k].sample([CONFIG.BATCH_SIZE])).to(CONFIG.DEVICE)\n",
    "                for k in range(CONFIG.K)\n",
    "            ]\n",
    "            \n",
    "            maps_opt.zero_grad()\n",
    "            loss = 0\n",
    "            for k in range(CONFIG.K):\n",
    "                mapped_x_k, reg = maps[k](data[k], reg=True)  # [B, N]\n",
    "                cost = strong_cost(h(data[k]), h(mapped_x_k))  # [B, 1]\n",
    "                cost -= pots[k](mapped_x_k)  # [B, 1]\n",
    "                cost += reg_coeff * torch.unsqueeze(reg, -1)\n",
    "                cost = cost.mean(dim=0)\n",
    "                loss += CONFIG.LAMBDAS[k] * cost\n",
    "\n",
    "            loss.backward()\n",
    "            maps_opt.step()\n",
    "            maps_sched.step()\n",
    "        \n",
    "        # unfreezing potentials \n",
    "        # freezing maps\n",
    "        unfreeze(pots)\n",
    "        freeze(maps)\n",
    "        \n",
    "        # outer optimiztion\n",
    "        pots_opt.zero_grad()\n",
    "        loss=0\n",
    "        cost = None\n",
    "        for k in range(CONFIG.K):\n",
    "            mapped_x_k = maps[k](data[k])  # [B, N]\n",
    "            cost = torch.zeros((CONFIG.BATCH_SIZE, 1), device=CONFIG.DEVICE)\n",
    "            cost -= pots[k](mapped_x_k)  # [B, 1]\n",
    "            cost = cost.mean(dim=0)\n",
    "            loss += CONFIG.LAMBDAS[k] * cost\n",
    "        \n",
    "        loss = -1*loss\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        pots_opt.step()\n",
    "        pots_sched.step()\n",
    "        \n",
    "        \n",
    "        # plotting part\n",
    "        if epoch % 10 ==0 :\n",
    "            data = [h_inv(twister_data[k].sample([1_000])).to(CONFIG.DEVICE)\n",
    "                        for k in range(CONFIG.K)]\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            fig, (ax, ax_l) = plt.subplots(1, 2, figsize=(12.8, 4.8))\n",
    "            for k in range(CONFIG.K):\n",
    "                d = maps[k](data[k]).detach().cpu()\n",
    "                ax.scatter(data[k][:,0].cpu(),data[k][:,1].cpu(),edgecolor='black',label=f'data {k+1}')\n",
    "                ax.scatter(d[:,0],d[:,1],edgecolor='black',label=f'barycenter {k+1}')\n",
    "                ax.grid()\n",
    "                ax.legend()\n",
    "                ax.set_xlim(-8, 8)\n",
    "                ax.set_ylim(-8, 8)\n",
    "                \n",
    "            ax_l.plot(losses)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62dc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0, avoid_benchmark_noise=True)\n",
    "\n",
    "maps_ur = nn.ModuleList([\n",
    "    DeterministicMap(CONFIG.INPUT_DIM, CONFIG.HIDDEN_DIMS, CONFIG.OUTPUT_DIM_MAP)\n",
    "    for _ in range(CONFIG.K)\n",
    "]).to(CONFIG.DEVICE)\n",
    "maps_opt, maps_sched = get_opt_sched(maps_ur, CONFIG.NUM_EPOCHS * CONFIG.INNER_ITERATIONS)\n",
    "\n",
    "pots_ur = Pots(\n",
    "    CONFIG.LAMBDAS,\n",
    "    CONFIG.INPUT_DIM,\n",
    "    *CONFIG.HIDDEN_DIMS,\n",
    "    CONFIG.OUTPUT_DIM_POT\n",
    ").to(CONFIG.DEVICE)\n",
    "pots_opt, pots_sched = get_opt_sched(pots_ur, CONFIG.NUM_EPOCHS)\n",
    "\n",
    "train(maps_ur, maps_opt, maps_sched, pots_ur, pots_opt, pots_sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970dfe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0, avoid_benchmark_noise=True)\n",
    "\n",
    "maps_kl_1 = nn.ModuleList([\n",
    "    GaussianMap(\n",
    "        CONFIG.INPUT_DIM,\n",
    "        CONFIG.HIDDEN_DIMS,\n",
    "        CONFIG.OUTPUT_DIM_MAP,\n",
    "        CONFIG.PRIOR_MEAN,\n",
    "        CONFIG.PRIOR_COV,\n",
    "    )\n",
    "    for _ in range(CONFIG.K)\n",
    "]).to(CONFIG.DEVICE)\n",
    "maps_opt, maps_sched = get_opt_sched(maps_kl_1, CONFIG.NUM_EPOCHS * CONFIG.INNER_ITERATIONS)\n",
    "\n",
    "pots_kl_1 = Pots(\n",
    "    CONFIG.LAMBDAS,\n",
    "    CONFIG.INPUT_DIM,\n",
    "    *CONFIG.HIDDEN_DIMS,\n",
    "    CONFIG.OUTPUT_DIM_POT\n",
    ").to(CONFIG.DEVICE)\n",
    "pots_opt, pots_sched = get_opt_sched(pots_kl_1, CONFIG.NUM_EPOCHS)\n",
    "\n",
    "train(maps_kl_1, maps_opt, maps_sched, pots_kl_1, pots_opt, pots_sched, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa60537",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0, avoid_benchmark_noise=True)\n",
    "\n",
    "maps_ed_1 = nn.ModuleList([\n",
    "    GaussianMap(\n",
    "        CONFIG.INPUT_DIM,\n",
    "        CONFIG.HIDDEN_DIMS,\n",
    "        CONFIG.OUTPUT_DIM_MAP,\n",
    "        CONFIG.PRIOR_MEAN,\n",
    "        CONFIG.PRIOR_COV,\n",
    "    )\n",
    "    for _ in range(CONFIG.K)\n",
    "]).to(CONFIG.DEVICE)\n",
    "maps_opt, maps_sched = get_opt_sched(maps_ed_1, CONFIG.NUM_EPOCHS * CONFIG.INNER_ITERATIONS)\n",
    "\n",
    "pots_ed_1 = Pots(\n",
    "    CONFIG.LAMBDAS,\n",
    "    CONFIG.INPUT_DIM,\n",
    "    *CONFIG.HIDDEN_DIMS,\n",
    "    CONFIG.OUTPUT_DIM_POT\n",
    ").to(CONFIG.DEVICE)\n",
    "pots_opt, pots_sched = get_opt_sched(pots_ed_1, CONFIG.NUM_EPOCHS)\n",
    "\n",
    "train(maps_ed_1, maps_opt, maps_sched, pots_ed_1, pots_opt, pots_sched, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8056e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178b33fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian_pdf(mean, covar, n_points, ax):\n",
    "#     span = 10 * torch.sqrt(torch.diag(covar).max())\n",
    "#     x = mean[0] + torch.linspace(-1, 1, n_points) * span\n",
    "#     y = mean[1] + torch.linspace(-1, 1, n_points) * span\n",
    "    x = torch.linspace(*ax.get_xlim(), n_points)\n",
    "    y = torch.linspace(*ax.get_ylim(), n_points)\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "    distr = TD.MultivariateNormal(mean, covariance_matrix=covar)\n",
    "    Z = torch.sqrt(-distr.log_prob(torch.stack((X, Y), axis=-1)))\n",
    "    \n",
    "    ax.contour(X, Y, Z, levels=10, alpha=0.3, linewidths=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b686cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bary_i(map_nets, samplers, ax, i, n_samples=512, n_maps=0, n_arrows_per_map=1, seed=0):\n",
    "    seed_everything(seed, avoid_benchmark_noise=True)\n",
    "    \n",
    "    n_arrows = n_maps * n_arrows_per_map\n",
    "    X = h_inv(samplers[i].sample((n_samples,))).to(CONFIG.DEVICE)\n",
    "    if n_maps > 0:\n",
    "        Xm = h_inv(samplers[i].sample((n_maps,))).to(CONFIG.DEVICE)\n",
    "        Xm = torch.tile(Xm, (n_arrows_per_map, 1))\n",
    "        X = torch.cat((X, Xm), dim=0)\n",
    "        \n",
    "    Y = map_nets[i](X)\n",
    "    X_np = X.detach().cpu().numpy()\n",
    "    Y_np = Y.detach().cpu().numpy()\n",
    "        \n",
    "    def alpha_color(color_rgb, alpha=0.5):\n",
    "        color_rgb = np.asanyarray(color_rgb)\n",
    "        alpha_color_rgb = 1. - (1. - color_rgb) * alpha\n",
    "        return alpha_color_rgb\n",
    "    \n",
    "    def darker(c): return tuple(x * 0.85 for x in c)\n",
    "    \n",
    "    cols = mpl.colormaps[\"tab10\"].colors\n",
    "    col_bary = alpha_color(mpl.colormaps[\"tab10\"].colors[CONFIG.K])\n",
    "    \n",
    "    p4 = ax.scatter(\n",
    "        X_np[:n_samples, 0], \n",
    "        X_np[:n_samples, 1],\n",
    "        edgecolors=alpha_color((0, 0, 0)),\n",
    "        color=alpha_color(cols[i]),\n",
    "        zorder=0,\n",
    "        linewidth=.5,\n",
    "    )\n",
    "    p1 = ax.scatter(\n",
    "        Y_np[:n_samples, 0], \n",
    "        Y_np[:n_samples, 1],\n",
    "        edgecolors=(0, 0, 0), \n",
    "        color=col_bary,\n",
    "        zorder=0,\n",
    "        linewidth=.5,\n",
    "    )\n",
    "\n",
    "    if n_arrows > 0:\n",
    "        p3 = ax.scatter(\n",
    "            X_np[-n_arrows:, 0],\n",
    "            X_np[-n_arrows:, 1],\n",
    "            linewidth=.5,\n",
    "            edgecolors='black', \n",
    "            color=cols[i], \n",
    "            zorder=2,\n",
    "        )\n",
    "        p2 = ax.scatter(\n",
    "            Y_np[-n_arrows:, 0], \n",
    "            Y_np[-n_arrows:, 1],\n",
    "            linewidth=.5, \n",
    "            edgecolors='black', \n",
    "            color=cols[CONFIG.K + 2],\n",
    "            zorder=2,\n",
    "        )\n",
    "        ax.quiver(\n",
    "            X_np[-n_arrows:, 0], \n",
    "            X_np[-n_arrows:, 1],\n",
    "            Y_np[-n_arrows:, 0] - X_np[-n_arrows:, 0],\n",
    "            Y_np[-n_arrows:, 1] - X_np[-n_arrows:, 1],\n",
    "            angles='xy', \n",
    "            scale_units='xy', \n",
    "            scale=0.95, \n",
    "            width=.005, \n",
    "            zorder=1, \n",
    "            headwidth=0.0,\n",
    "            headlength=0.0,\n",
    "        )\n",
    "        \n",
    "#     fig.legend(\n",
    "#         [\n",
    "#             (p1, p2),\n",
    "#             (p3, p4),\n",
    "#         ],\n",
    "#         [\n",
    "#             f\"$y \\\\sim T_{{{i + 1},\\\\phi}}(x_{i + 1},\\\\cdot)\\\\#\\\\mathbb{{S}}$\",\n",
    "#             f\"$x_{i + 1} \\\\sim \\mathbb{{P}}_{i + 1}$\",\n",
    "#         ],\n",
    "#         handler_map={tuple: HandlerTuple(ndivide=None)},\n",
    "#         loc=\"upper left\",\n",
    "#         prop={\"size\": 13.5},\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a962f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BARY_IDX = 0\n",
    "N_SAMPLES = 128\n",
    "N_MAPS = 10\n",
    "N_ARROWS_PER_MAP = 3\n",
    "\n",
    "fig, (ax_gt, ax_ur, ax_kl_1, ax_ed_1) = plt.subplots(\n",
    "    ncols=4,\n",
    "    figsize=(13, 3.2), \n",
    "    dpi=300,\n",
    "    sharey=True,\n",
    "    sharex=True,\n",
    ")\n",
    "\n",
    "for i, s in enumerate(twister_data):\n",
    "    ax_gt.scatter(\n",
    "        *h_inv(s.sample((512,))).cpu().T,\n",
    "        linewidth=.5, \n",
    "        edgecolors='black',\n",
    "        label=f\"$x_{i + 1} \\\\sim \\mathbb{{P}}_{i + 1}$\",\n",
    "    )\n",
    "ax_gt.scatter(\n",
    "    *h_inv(Zgtdistrib.sample((512,))).cpu().T,\n",
    "    linewidth=.5, \n",
    "    edgecolors='black',\n",
    "    label=\"$y \\\\sim \\\\mathbb{Q}^*$\",\n",
    ")\n",
    "ax_gt.set_xlim((-8, 8))\n",
    "ax_gt.set_ylim((-8, 8))\n",
    "\n",
    "plot_bary_i(maps_ur, twister_data, ax_ur, BARY_IDX, N_SAMPLES, N_MAPS, N_ARROWS_PER_MAP)\n",
    "plot_gaussian_pdf(CONFIG.PRIOR_MEAN.cpu(), CONFIG.PRIOR_COV.cpu(), 50, ax_ur)\n",
    "\n",
    "plot_bary_i(maps_kl_1, twister_data, ax_kl_1, BARY_IDX, N_SAMPLES, N_MAPS, N_ARROWS_PER_MAP)\n",
    "plot_gaussian_pdf(CONFIG.PRIOR_MEAN.cpu(), CONFIG.PRIOR_COV.cpu(), 50, ax_kl_1)\n",
    "\n",
    "plot_bary_i(maps_ed_1, twister_data, ax_ed_1, BARY_IDX, N_SAMPLES, N_MAPS, N_ARROWS_PER_MAP)\n",
    "plot_gaussian_pdf(CONFIG.PRIOR_MEAN.cpu(), CONFIG.PRIOR_COV.cpu(), 50, ax_ed_1)\n",
    "\n",
    "fig.legend(loc=\"upper center\")\n",
    "\n",
    "plt.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e79a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a4da6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abad0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c31ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec94710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
