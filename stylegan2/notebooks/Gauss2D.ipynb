{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.linalg import sqrtm\n",
    "import matplotlib.pyplot as plt\n",
    "import geotorch\n",
    "import geomloss\n",
    "import ot\n",
    "from matplotlib import collections  as mc\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import wandb\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from typing import Callable, Tuple, Union\n",
    "\n",
    "\n",
    "import src.distributions as distributions\n",
    "\n",
    "from src.utils import freeze, unfreeze, fig2img  \n",
    "from src.models import linear_model\n",
    "from src.cost import strong_cost\n",
    "from src import bar_benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a17b5",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48167958",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 2 # or 4,8,16,64,128\n",
    "\n",
    "INPUT_DIM = DIM\n",
    "HIDDEN_DIMS = [128,128]\n",
    "OUTPUT_DIM_POT = 1\n",
    "OUTPUT_DIM_MAP = INPUT_DIM\n",
    "LR = 5e-4\n",
    "\n",
    "NUM_SAMPLES = 10_000\n",
    "NUM_EPOCHS = 10000\n",
    "PLOT_FREQ = 200\n",
    "SCORE_FREQ = 1\n",
    "BATCH_SIZE=1000\n",
    "INNER_ITERATIONS = 10\n",
    "\n",
    "K = 3\n",
    "LAMBDAS = np.array([0.25, 0.25, 0.5])\n",
    "\n",
    "assert K == len(LAMBDAS)   \n",
    "assert torch.cuda.is_available()\n",
    "DEVICE = 'cuda'\n",
    "DEVICE_IDS = [i for i in range(torch.cuda.device_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b18682",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASE = {\n",
    "    'type' : 'EigWarp', \n",
    "    'sampler' : 'Gaussians',\n",
    "    'params' : {'num' : K, 'alphas' : LAMBDAS, 'min_eig' : .5, 'max_eig' : 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0xB00BA\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "EXP_NAME = f'EOTbary_WINnets_{DIM}_{K}_{INNER_ITERATIONS}'\n",
    "OUTPUT_PATH = '../checkpoints/EOTbary_WINnets_{}_{}_{}/'.format(DIM, K, INNER_ITERATIONS)\n",
    "\n",
    "if OUTPUT_PATH is not None:\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd0b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    CASE=CASE['sampler'],\n",
    "    BATCH_SIZE=BATCH_SIZE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e07f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(name=EXP_NAME, project='egbarycenters', config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b8467c",
   "metadata": {},
   "source": [
    "## Initializing distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42fa5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CASE['type'] == 'EigWarp':\n",
    "    if CASE['sampler'] == 'Gaussians':\n",
    "        sampler = distributions.StandardNormalSampler(dim=DIM)\n",
    "        \n",
    "    benchmark = bar_benchmark.EigenWarpBenchmark(sampler, **CASE['params'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a158dc",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "class Identity:\n",
    "    pass\n",
    "\n",
    "if benchmark.bar_sampler is not None:\n",
    "    pca.fit(benchmark.bar_sampler.sample(100000).cpu().detach().numpy())\n",
    "elif benchmark.gauss_bar_sampler is not None:\n",
    "    pca.fit(benchmark.gauss_bar_sampler.sample(100000).cpu().detach().numpy())\n",
    "else:\n",
    "    pca = Identity()\n",
    "    pca.transform = lambda x: x\n",
    "    \n",
    "# No PCA for dim=2\n",
    "if DIM == 2:\n",
    "    pca = Identity()\n",
    "    pca.transform = lambda x: x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94efe142",
   "metadata": {},
   "source": [
    "## Models for the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39624362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_f_pot(idx, nets, config):\n",
    "    \n",
    "    def f_pot(x):\n",
    "        res = 0.0\n",
    "        for i, (net, lmbd) in enumerate(zip(nets, LAMBDAS)):\n",
    "            \n",
    "            if i == idx:\n",
    "                res += net(x)\n",
    "            else:\n",
    "                res -= lmbd * net(x) / (K - 1) / LAMBDAS[idx]\n",
    "        return res\n",
    "    \n",
    "    return f_pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464fba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = nn.Sequential(\n",
    "    nn.Linear(DIM, max(100, 2*DIM)),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(max(100, 2*DIM), max(100, 2*DIM)),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(max(100, 2*DIM), max(100, 2*DIM)),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(max(100, 2*DIM), OUTPUT_DIM_POT)\n",
    ").cuda()\n",
    "\n",
    "T = nn.Sequential(\n",
    "    nn.Linear(DIM, max(100, 2*DIM)),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(max(100, 2*DIM), max(100, 2*DIM)),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(max(100, 2*DIM), max(100, 2*DIM)),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(max(100, 2*DIM), OUTPUT_DIM_MAP)\n",
    ").cuda()\n",
    "\n",
    "g = [deepcopy(D).to(DEVICE) for _ in range(K)]\n",
    "\n",
    "param_nets = [net.parameters() for net in  g]\n",
    "g_opt = torch.optim.Adam(itertools.chain(*param_nets), LR)\n",
    "\n",
    "f_pots = [make_f_pot(i, g, LAMBDAS) for i in range(K)]\n",
    "\n",
    "maps = [deepcopy(T).to(DEVICE) for _ in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d72d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_nets = [mp.parameters() for mp in  maps]\n",
    "maps_opt = torch.optim.Adam(itertools.chain(maps[0].parameters(),\n",
    "                                            maps[1].parameters(),\n",
    "                                            maps[2].parameters()),\n",
    "                               LR )\n",
    "\n",
    "g_scheduler = torch.optim.lr_scheduler.MultiStepLR(maps_opt, milestones=[5000], gamma=0.5)\n",
    "maps_scheduler = torch.optim.lr_scheduler.MultiStepLR(g_opt, milestones=[5000], gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580685dd",
   "metadata": {},
   "source": [
    "## Plotters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a3e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(ax1, ax2):\n",
    "    cols = plt.get_cmap(\"Dark2\").colors\n",
    "    Xs = []\n",
    "    for i, distr in enumerate(benchmark.samplers):\n",
    "        X = distr.sample(512,).detach().cpu().numpy()\n",
    "        Xs.append(X)\n",
    "        ax1.scatter(\n",
    "            X[:, 0], X[:, 1],\n",
    "            label=f\"$x_{{{i + 1}}} \\\\sim \\\\mathbb{{P}}_{{{i + 1}}}$\", \n",
    "            edgecolors=alpha_color((0, 0, 0)), color=alpha_color(cols[i]), linewidth=.5,\n",
    "        )\n",
    "    \n",
    "    Xgt = benchmark.gauss_bar_sampler.sample(512).detach().cpu().numpy()\n",
    "    ax2.scatter(\n",
    "        Xgt[:, 0], Xgt[:, 1],\n",
    "        label=r\"$x \\sim \\mathbb{Q}_*$\", \n",
    "        edgecolors='black', color=cols[K + 1], linewidth=.5,\n",
    "    )\n",
    "    ax1.legend(ncol=2, loc=\"upper left\", prop={\"size\": 12})\n",
    "    ax2.legend(ncol=2, loc=\"upper left\", prop={\"size\": 12})\n",
    "\n",
    "def alpha_color(color_rgb, alpha=0.5):\n",
    "    color_rgb = np.asanyarray(color_rgb)\n",
    "    alpha_color_rgb = 1. - (1. - color_rgb) * alpha\n",
    "    return alpha_color_rgb\n",
    "\n",
    "def plot_bary_i(map_, sampler, ax, i, n_samples=512, n_maps=0, n_arrows_per_map=1):\n",
    "    global p1\n",
    "    n_arrows = n_maps * n_arrows_per_map\n",
    "    X = benchmark.samplers[i].sample(n_samples,).to(DEVICE)\n",
    "    if n_maps > 0:\n",
    "        Xm = benchmark.samplers[i].sample(n_maps,).to(DEVICE)\n",
    "        Xm = torch.tile(Xm, (n_arrows_per_map, 1))\n",
    "        X = torch.concatenate((X, Xm), dim=0)\n",
    "        \n",
    "        \n",
    "    Y = map_(X).to(DEVICE)\n",
    "    X_np = X.detach().cpu().numpy()\n",
    "    Y_np = Y.detach().cpu().numpy()\n",
    "    \n",
    "    def darker(c): return tuple(x * 0.85 for x in c)\n",
    "    \n",
    "    cols = plt.get_cmap(\"Dark2\").colors\n",
    "    col_bary = plt.get_cmap(\"tab10\").colors[K]\n",
    "    p4 = ax.scatter(\n",
    "        X_np[:n_samples, 0], X_np[:n_samples, 1],\n",
    "        edgecolors=alpha_color((0, 0, 0)), color=alpha_color(cols[i]), zorder=0, linewidth=.5,\n",
    "    )\n",
    "    p1 = ax.scatter(\n",
    "        Y_np[:n_samples, 0], Y_np[:n_samples, 1],\n",
    "        edgecolors=(0, 0, 0), color=col_bary, zorder=0, linewidth=.5,\n",
    "    )\n",
    "    p3 = ax.scatter(\n",
    "            X_np[-n_arrows:, 0], X_np[-n_arrows:, 1],\n",
    "            linewidth=.5, edgecolors='black', color=cols[i], zorder=2,\n",
    "        )\n",
    "    p2 = ax.scatter(\n",
    "        Y_np[-n_arrows:, 0], Y_np[-n_arrows:, 1],\n",
    "        linewidth=.5, edgecolors='black', color=cols[K + 2], zorder=2,\n",
    "    )\n",
    "    if n_arrows > 0:\n",
    "        ax.quiver(\n",
    "            X_np[-n_arrows:, 0], X_np[-n_arrows:, 1],\n",
    "            Y_np[-n_arrows:, 0] - X_np[-n_arrows:, 0], Y_np[-n_arrows:, 1] - X_np[-n_arrows:, 1],\n",
    "            angles='xy', scale_units='xy', scale=0.95, width=.005, zorder=1, headwidth=0.0, headlength=0.0,\n",
    "        )\n",
    "        \n",
    "    ax.legend(\n",
    "        [\n",
    "            (p1, p2),\n",
    "            (p3, p4),\n",
    "        ], [\n",
    "            f\"$x_{i + 1} \\\\sim \\\\pi^*_{i + 1}(\\\\cdot \\\\mid x_{i + 1})$\",\n",
    "            f\"$x_{i + 1} \\\\sim \\mathbb{{P}}_{i + 1}$\",\n",
    "        ],\n",
    "        handler_map={tuple: HandlerTuple(ndivide=None)},\n",
    "        loc=\"upper left\",\n",
    "        prop={\"size\": 12},\n",
    "    )\n",
    "\n",
    "def plot_bary(maps, benchmark, arrows=True):\n",
    "    N_SAMPLES = 512\n",
    "    N_MAPS = 5\n",
    "    N_ARROWS_PER_MAP = 3\n",
    "    \n",
    "    n_maps = N_MAPS if arrows else 0\n",
    "    \n",
    "    fig, axs = plt.subplots(\n",
    "        ncols=K + 2,\n",
    "        figsize=(18.75, 3.75),\n",
    "        sharex=True, sharey=True,\n",
    "        dpi=200,\n",
    "    )\n",
    "        \n",
    "    plot_distributions(axs[0], axs[1])\n",
    "    axs[0].set_xlim(-7, 7)\n",
    "    axs[0].set_ylim(-7, 7)\n",
    "    axs[1].set_xlim(-7, 7)\n",
    "    axs[1].set_ylim(-7, 7)\n",
    "    \n",
    "    for i, (map_, sampler, ax) in enumerate(zip(maps, benchmark.samplers, axs[2:])):\n",
    "        plot_bary_i(map_, sampler, ax, i, N_SAMPLES, n_maps, N_ARROWS_PER_MAP)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5e8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bary(maps, benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e123f675",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821cd5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_forward_maps(benchmark, maps, lambdas, score_size=1024):\n",
    "    assert (benchmark.gauss_bar_maps is not None) and (benchmark.gauss_bar_sampler is not None)\n",
    "    L2_UVP_arr = []\n",
    "    for k in range(benchmark.num):\n",
    "        X = benchmark.samplers[k].sample(score_size)\n",
    "        with torch.no_grad():\n",
    "            X_push = maps[k](X)\n",
    "        with torch.no_grad():\n",
    "            X_push_true = benchmark.gauss_bar_maps[k](X)\n",
    "            L2_UVP_arr.append(\n",
    "                100 * (((X_push - X_push_true) ** 2).sum(dim=1).mean() / benchmark.gauss_bar_sampler.var).item()\n",
    "            )\n",
    "    weighted_L2_UVP = sum(lambda_ * L2_UVP for (lambda_, L2_UVP) in zip(lambdas, L2_UVP_arr))\n",
    "    return weighted_L2_UVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683283eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_forward_maps(benchmark, maps, LAMBDAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d53d49",
   "metadata": {},
   "source": [
    "## Training block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e14455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eed7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_plot_epoch = -1\n",
    "last_score_epoch = -1\n",
    "best_L2_UVP = 1000\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # freezing potentials \n",
    "    # unfreezing maps\n",
    "    for idx in range(K):\n",
    "        freeze(g[idx])\n",
    "        unfreeze(maps[idx])\n",
    "\n",
    "\n",
    "    #inner loop\n",
    "    for it in range(INNER_ITERATIONS):\n",
    "        data = [s.sample(BATCH_SIZE).to(DEVICE) for s in benchmark.samplers]\n",
    "\n",
    "        maps_opt.zero_grad()\n",
    "        loss = 0\n",
    "        for k in range(K):\n",
    "            mapped_x_k = maps[k](data[k]) #[B,N] \n",
    "            cost = strong_cost(data[k],mapped_x_k) #[B,1]\n",
    "            cost -= f_pots[k](mapped_x_k)#[B,1]\n",
    "            cost = cost.mean(dim=0)\n",
    "            loss += LAMBDAS[k]*cost\n",
    "\n",
    "        loss.backward()\n",
    "        maps_opt.step()\n",
    "        maps_scheduler.step()\n",
    "\n",
    "    # unfreezing potentials \n",
    "    # freezing maps\n",
    "    for idx in range(K):\n",
    "        unfreeze(g[idx])\n",
    "        freeze(maps[idx])\n",
    "\n",
    "    # outer optimiztion\n",
    "    g_opt.zero_grad()\n",
    "    loss=0\n",
    "    for k in range(K):\n",
    "        mapped_x_k = maps[k](data[k]) #[B,N]\n",
    "        cost = strong_cost(data[k],mapped_x_k) #[B,1]\n",
    "        cost -= f_pots[k](mapped_x_k)#[B,1]\n",
    "        cost = cost.mean(dim=0)\n",
    "        loss += LAMBDAS[k]*cost\n",
    "\n",
    "    loss = -1*loss\n",
    "    wandb.log({f'Loss' : loss.item()}, step=epoch)\n",
    "    loss.backward()\n",
    "    g_opt.step()\n",
    "    g_scheduler.step()\n",
    "\n",
    "    if (epoch - last_plot_epoch >= PLOT_FREQ):\n",
    "        last_plot_epoch = epoch  \n",
    "\n",
    "        fig = plot_bary(maps, benchmark, arrows=False)\n",
    "        fig.tight_layout();\n",
    "        wandb.log({'Pca' : [wandb.Image(fig2img(fig))]}, step=epoch)\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "    if (epoch - last_score_epoch >= SCORE_FREQ):\n",
    "        last_score_epoch = epoch\n",
    "\n",
    "        if benchmark.gauss_bar_sampler is not None:\n",
    "            L2_UVP = score_forward_maps(benchmark, maps, LAMBDAS, score_size=1024)\n",
    "            wandb.log({f'L2_UVP' : L2_UVP}, step=epoch)\n",
    "\n",
    "            if L2_UVP < best_L2_UVP:\n",
    "                best_L2_UVP = L2_UVP\n",
    "                for k in range(benchmark.num):\n",
    "                    freeze(maps[k])\n",
    "                    torch.save(maps[k].state_dict(), OUTPUT_PATH + 'maps{}_best.pt'.format(k))\n",
    "                    np.savez(OUTPUT_PATH + 'metrics.npz', L2_UVP=best_L2_UVP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f550f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a32ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
